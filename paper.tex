% ****** Start of file aipsamp.tex ******
%
%   This file is part of the AIP files in the AIP distribution for REVTeX 4.
%   Version 4.1 of REVTeX, October 2009
%
%   Copyright (c) 2009 American Institute of Physics.

% Use this file as a source of example code for your aip document.
% Use the file aiptemplate.tex as a template for your document.
\documentclass[%
	aip,
	jmp,%
	amsmath,amssymb,
	%preprint,%
	reprint,%
	%author-year,%
	%author-numerical,%
]{revtex4-1}
%\extrafloats{1000}
\usepackage{morefloats}% Include figure files
\usepackage{graphicx}% Include figure files
\usepackage{grffile}
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines
\usepackage{multirow}
\usepackage{color} % for the notes
\usepackage{etex}
\reserveinserts{58}
%\usepackage{morefloats}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{amsmath}
\hypersetup{
	colorlinks,
	linkcolor={red!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}

\usepackage{xr}
\externaldocument{supportingInformation}
\maxdeadcycles=1000

\usepackage{placeins}
\begin{document}

\preprint{XXXXX (preprint)}

%\title[Evolution of interaction networks]{On the evolution of interaction networks: primitive typology of vertex, prominence of measures and activity statistics}% Force line breaks with \\
%\title[Evolution of interaction networks]{On the evolution of interaction networks: a primitive typology of vertex}% Force line breaks with \\
%\title[Stability of interaction networks]{Stability in human interaction networks: sector relative sizes, prominence of topological measures and time activity statistics.}% Force line breaks with \\
%\title[Stability in human interaction networks]{Sector relative sizes and topological metrics time stability in human interaction networks}% Force line breaks with \\
\title[Distances between histograms]{A distance metric between histograms
through the the Kolmogorov-Smirnov test statistic: specification, measures reference and example uses}% Force line breaks with \\
\author{Renato Fabbri}%
\homepage{http://ifsc.usp.br/~fabbri/}
\email{fabbri@usp.br}
\affiliation{ 
	S\~ao Carlos Institute of Physics, University of S\~ao Paulo (IFSC/USP),
	PO Box 369, 13560-970, S\~ao Carlos, SP, Brazil %\\This line break forced with \textbackslash\textbackslash
}

\date{\today}% It is always \today, today,
%  but any date may be explicitly specified

\begin{abstract}
This document presents reference values for a distance metric
derived from the Kolmogorov-Smirnov test statistic $D_{n,n'}$.
Each measure of $D_{n,n'}$ is a distance between two histograms,
which is normalized by the number of observations in each sample
to yield p-values $c'$, i.e. values for which 
higher levels of significance $\alpha>c'$ implies the rejection of the null hypothesis.
Benchmarks for the implementation are delivered by comparing samples from known distributions.
Pattern examples in real data enables further
insight in the robustness and power of $c'$.
\end{abstract}

\pacs{05.10-a,}% PACS, the Physics and Astronomy
\keywords{Kolmogorov-Smirnov test, statistic, benchmark, distance measure, histogram}
\maketitle
\section{Introduction}\label{sec:intro}

% $D_{n,n'}$
%depicted in Figure~\ref{fig:kolms}


Be $F_{1,n}$ and $F_{2,n'}$ two empirical cumulative distributions,
where $n$ and $n'$ are the number of observations on each sample.
The two-sample Kolmogorov-Smirnov test rejects the null hypothesis
that the histograms are the outcome of the same underlying distribution
if:
\begin{equation}\label{eq:ks}
D_{n,n'} > c(\alpha)\sqrt{\frac{n+n'}{nn'}}
\end{equation}

\noindent where $D_{n,n'}=sup_x[F_{1,n}-F_{2,n'}]$ as in Figure~\ref{fig:dnn}
and $c(\alpha)$ is related to the critical region $\alpha$ by:

\begin{table}[h!]
\centering
\begin{tabular}{|l||c|c|c|c|c|c|}\hline
$\alpha$    & 0.1  & 0.05 & 0.025 & 0.01 & 0.005 & 0.001 \\\hline
$c(\alpha)$ & 1.22 & 1.36 & 1.48  & 1.63 & 1.73  & 1.95  \\\hline
\end{tabular}
\end{table}

If distributions are drawn from empirical data, $D_{n,n'}$ is given as are $n$ and $n'$.
All terms in equation~\ref{eq:ks} are positive and $c(\alpha)$ can be isolated:

\begin{equation}\label{eq:ks2}
c(\alpha) < \frac{D_{n,n'}}{\sqrt{\frac{n+n'}{nn'}}} = c'
\end{equation}

%Tables~\ref{tab:kolSub}-\ref{tab:kolPctInter} are populated with values for $c'(\alpha)$
When $c'$ is high, low values of $\alpha$ favor rejecting the null hypothesis.

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.44\textwidth]{figs/Dnn}
	\caption{The Kolmogorov-Smirnov statistic $D_{n,n'}$: the maximum difference between
		two cumulative distribution functions.}
	\label{fig:dnn}
\end{figure}



Hight values of $c'$ favor rejecting the null hypothesis.
For example, if $\alpha=0.01$, then $c'$ greater than $1.7$,
rejects the null hypothesis and
suggests that $F_{n}$ and $F_{n'}$
are outcomes of different distributions.
Of core importance in this study is to regard the $c'$ statistic
as a measure of distance between both distributions~\cite{kolm}.
The main contribution of the following sections is the
explicit display of reference values of $c'$
from which one might derive knowledge from
$c'$ measures or even from a single value of $c'$.

\subsection{Philosophical and technological note}
Difference and equivalence is of central role in human cognition,
philosophy and science.
This fact is so deeply recognized that thinkers often reduce
thought to classifications, e.g. through the
mathematical concept of equivalence classes~\cite{deleuze}.
Histograms are very immediate and informative
roughly wherever there is a phenomenon of interest which can yield measurements.
This present document should enable conclusions to be drawn about 
the equivalence (and difference)
of the processes underlying sets of measurements for a very
broad range of phenomena.
The following tables 
validate the mathematical framework
and the software implementation.

\subsection{Document outline}
Section~\ref{sec:simulations} expose reference values drawn from simulations.
Section~\ref{sec:empirical} exemplifies the use of such reference values
to make sense of phenomena.
Section~\ref{sec:conc} hold final remarks.
Software and data specification are given in Appendix~\ref{ap:soft}.


\section{References through simulations}\label{sec:simulations}
On every case, values of $c'$ are given for simulations involving
at least normal, uniform, triangular, Weibull and power-law distributions.

\subsection{When the null hypothesis is true}
If the null hypothesis is true, than the number
of rejections of the null hypothesis (that is: $c'>c(\alpha)$)
in $N_c$ comparisons should not exceed $\alpha N_c$.
To verify this, let $C'=\{c_i'\}$ be a set of $c'$ measures,
and $C'(\alpha)=\{c' : c'>c(\alpha)\}$.
Be $|C'(\alpha)|$ the cardinality of $C'(\alpha)$,
i.e. the number of comparisons in which the two-sample Kolmogorov-Smirnov
test rejects the null hypothesis for a given $\alpha$.

The most important result of this section is that
$|C'(\alpha)|$ rarely exceeds $\alpha N_c$,
 where $N_c$ is the number of comparisons made,
no matter what probability distribution type
or the specific setting.
Also important are that
$c'>c(\alpha)$ in many cases
and that $\alpha$ is a good estimate of the upper limit of the probability
of such an event.
%\begin{itemize}
%	\item $c'>c(\alpha)$ in many cases, and $\alpha N_c$ is a good upper limit to keep in mind.
%	\item 
%\end{itemize}

% Input tables
% any plot? If std is ~stable, plots of the mean of c~(\alpha) are compact and informative
\input{tables/tabNormNull}
\input{tables/tabUniformNull}
\input{tables/tabWeibullNull}
\input{tables/tabPowerNull}

\subsection{When the null hypothesis if false}
The $m(c')$ are median values of $c'$.
$\overline{C'(\alpha)}=\frac{|C'(\alpha)|}{N_c}$ is the fraction
of rejection of the null hypothesis with critical region $\alpha$.
\input{tables/tabNormDiff3}
\input{tables/tabNormDiffMean}
\input{tables/tabUniformDiffSpread}
\input{tables/tabUniformDiffMean}
\input{tables/tabWeibullDiffShape}
\input{tables/tabPowerDiffShape}
%\input{tables/tabNormDiff1}
%\input{tables/tabNormDiff2}


% distribuicoes normal, uniforme, weibul
% distribuicao de lei de potencia
% contemplar numeros diferentes de bins, de amostras e de distribuicoes
% enquanto mantemos mudando os parametros
\section{Example uses in empirical data}\label{sec:empirical}
% nltk com machado, shakespeare e biblia
% arquivo de audio
% bytes quaisquer de algum arquivo?
% dados puxados da wikipedia, gmane ou ?


\section{Text}
\input{tables/textsGeneral}
\input{tables/textsDistances}
\input{tables/textsDistances2}
\input{tables/textsDistances2b}
\input{tables/textsDistances3}
\input{tables/textsDistances4}
\input{tables/textsDistances4b}
\section{Audio}
\input{tables/audioGeneral}
\input{tables/audioDistances}

\section{Music}
\input{tables/musicGeneral}
\input{tables/musicDistances}

\section{OS status}
\input{tables/osGeneral}
\input{tables/osDistances}

\section{Conclusions}\label{sec:conc}
The $c'$ metric is robust both to determine if
the distributions underlying the samples are the same
and to quantify the difference between probability distributions.
This work presents a set of benchmarks for making use $c'$.
Example analyses of real phenomena reveal patterns
without any of the training or clusterization usually involved in
classification routines.
Also, for making the analysis with other distributions
and data, or modifications on the measure of $c'$,
the rendering of this document is automatized in software.


\begin{acknowledgments}
	Financial support was obtained from CNPq (140860/2013-4,
	project 870336/1997-5), United Nations Development Program (contract: 2013/000566; project BRA/12/018) and FAPESP. 
	We are also grateful to developers and users of Python scientific tools.
\end{acknowledgments}


\appendix
\section{Software and data specifications}\label{ap:soft}
The measure of $c'$ is implemented in a small function within
the gmane Python package~\cite{gmanePack}.
The routines for generating the tables from simulated and empirical
data are grouped in separated files for easing further uses.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\nocite{*}
\bibliography{paper}% Produces the bibliography via BibTeX.

\end{document}
